package io.hainenber.vulpes;

import com.fasterxml.jackson.databind.ObjectMapper;
import io.hainenber.vulpes.entity.vulnerability.Vulnerability;
import io.hainenber.vulpes.opensearch.OpensearchClientFactory;
import org.eclipse.jgit.diff.DiffEntry;
import org.opensearch.client.opensearch.OpenSearchClient;
import org.opensearch.client.opensearch.core.BulkRequest;
import org.opensearch.client.opensearch.core.BulkResponse;
import org.opensearch.client.opensearch.core.bulk.BulkResponseItem;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.stereotype.Component;

import java.io.IOException;
import java.nio.file.Files;
import java.nio.file.Path;
import java.util.ArrayList;
import java.util.List;

@Component
public class VulnerabilityUpdater {
    private static final Logger log = LoggerFactory.getLogger(VulnerabilityUpdater.class);
    private static final ObjectMapper objectMapper = new ObjectMapper();
    private final OpensearchClientFactory opensearchClientFactory;

    @Value("${vulpes.github.advisory-database.path}")
    private String advisoryDatabasePath;

    @Value("${vulpes.opensearch.index}")
    private String indexName;

    public VulnerabilityUpdater(OpensearchClientFactory opensearchClientFactory) {
        this.opensearchClientFactory = opensearchClientFactory;
    }

    public boolean isOpensearchClusterOnline() {
        try {
            return opensearchClientFactory.getOpensearchClient().ping().value();
        } catch (Exception e) {
            return false;
        }
    }

    public void updateFromGitDiffs(List<DiffEntry> diffEntries) throws Exception {
        final OpenSearchClient openSearchClient = opensearchClientFactory.getOpensearchClient();
        final List<List<DiffEntry>> partitions = new ArrayList<>();
        final int BATCH_SIZE = 1000;

        // Split the diff entries into 1000-sized batches.
        for (int i = 0; i < diffEntries.size(); i++) {
            partitions.add(diffEntries.subList(i, Math.min(i + BATCH_SIZE, diffEntries.size())));
        }

        for (List<DiffEntry> partition : partitions) {
            final BulkRequest.Builder br = new BulkRequest.Builder();
            for (DiffEntry diffEntry : partition) {
                final String changedVulnerabilityPathString = diffEntry.getNewPath();
                final Path vulnerabilityPath = Path.of(advisoryDatabasePath, changedVulnerabilityPathString);
                try {
                    final String vulnerabilityString = Files.readString(vulnerabilityPath);
                    final Vulnerability changedVulnerability = objectMapper.readValue(vulnerabilityString, Vulnerability.class);
                    br.operations(op -> op
                            .index(idx -> idx
                                    .index(indexName)
                                    .id(changedVulnerability.getId())
                                    .document(changedVulnerability)
                            )
                    );
                } catch (IOException e) {
                    log.error("Failed to read vulnerability data from file {}: {}", vulnerabilityPath, e.toString());
                }
            }

            // Perform the bulk indexing for collected batch.
            final BulkResponse result = openSearchClient.bulk(br.build());
            if (result.errors()) {
                log.error("Failed to bulk index some vulnerabilities into OpenSearch cluster");
                for (BulkResponseItem item : result.items()) {
                    if (item.error() != null) {
                        log.error(item.error().reason());
                    }
                }
            } else {
                for (BulkResponseItem item : result.items()) {
                    log.info("Successfully index updated data for vulnerability {}",
                            item.id()
                    );
                }
            }
        }
    }
}
