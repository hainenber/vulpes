package io.hainenber.vulpes;

import com.fasterxml.jackson.core.JsonProcessingException;
import com.fasterxml.jackson.databind.ObjectMapper;
import io.hainenber.vulpes.entity.vulnerability.Vulnerability;
import io.hainenber.vulpes.opensearch.OpensearchClientFactory;
import io.hainenber.vulpes.repository.VulnerabilityRepository;
import org.opensearch.client.opensearch.OpenSearchClient;
import org.opensearch.client.opensearch._types.OpenSearchException;
import org.opensearch.client.opensearch._types.mapping.DateProperty;
import org.opensearch.client.opensearch._types.mapping.Property;
import org.opensearch.client.opensearch._types.mapping.TypeMapping;
import org.opensearch.client.opensearch.core.BulkRequest;
import org.opensearch.client.opensearch.core.BulkResponse;
import org.opensearch.client.opensearch.core.bulk.BulkResponseItem;
import org.opensearch.client.opensearch.indices.CreateIndexRequest;
import org.opensearch.client.opensearch.indices.GetIndexRequest;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.boot.context.event.ApplicationReadyEvent;
import org.springframework.context.event.EventListener;
import org.springframework.stereotype.Component;

import java.io.IOException;
import java.nio.file.Files;
import java.nio.file.Path;
import java.util.ArrayList;
import java.util.List;
import java.util.Objects;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.concurrent.atomic.AtomicReference;
import java.util.stream.Stream;

@Component
public class VulnerabilityInitialIngester {
    private static final Logger log = LoggerFactory.getLogger(VulnerabilityInitialIngester.class);
    private static final ObjectMapper objectMapper = new ObjectMapper();
    private static final Integer BATCH_LIMIT_FOR_BULK_INDEX = 1000;
    private final OpensearchClientFactory opensearchClientFactory;
    private final VulnerabilityRepository vulnerabilityRepository;

    @Value("${vulpes.github.advisory-database.path}")
    private String advisoryDatabasePath;

    @Value("${vulpes.opensearch.index}")
    private String indexName;

    @Value("${vulpes.load-data-from-scratch.postgresql")
    private Boolean loadDataFromScratchIntoPostgresql;

    @Value("${vulpes.load-data-from-scratch.opensearch")
    private Boolean loadDataFromScratchIntoOpensearch;

    public VulnerabilityInitialIngester(OpensearchClientFactory opensearchClientFactory, VulnerabilityRepository vulnerabilityRepository) {
        this.opensearchClientFactory = opensearchClientFactory;
        this.vulnerabilityRepository = vulnerabilityRepository;
    }

    private void populateIntoOpensearch(Stream<Path> vulnFileStream, AtomicInteger bulkCount) throws Exception {
        final OpenSearchClient openSearchClient = opensearchClientFactory.getOpensearchClient();
        final AtomicReference<BulkRequest.Builder> br = new AtomicReference<>(new BulkRequest.Builder());

        vulnFileStream.forEach(p -> {
            final String vulnerabilityFilename = p.getFileName().toString();
            if (vulnerabilityFilename.endsWith(".json")) {
                String vulnerabilityString = "";
                try {
                    vulnerabilityString = Files.readString(p);
                } catch (IOException e) {
                    log.error("Failed to read vulnerability data from file {}: {}", vulnerabilityFilename, e.toString());
                }
                if (!vulnerabilityString.isBlank()) {
                    try {
                        final Vulnerability vulnerability = objectMapper.readValue(vulnerabilityString, Vulnerability.class);
                        br.get().operations(op -> op
                                .index(idx -> idx
                                    .index(indexName)
                                    .id(vulnerability.getId())
                                    .document(vulnerability)
                                )
                        );
                        bulkCount.addAndGet(1);
                        if (bulkCount.get() >= BATCH_LIMIT_FOR_BULK_INDEX) {
                            final BulkResponse result = openSearchClient.bulk(br.get().build());
                            if (result.errors()) {
                                log.error("Failed to bulk index some vulnerabilities into OpenSearch cluster");
                                for (BulkResponseItem item: result.items()) {
                                    if (item.error() != null) {
                                        log.error(item.error().reason());
                                    }
                                }
                            } else {
                                log.info("Successfully bulk index {} vulnerabilities for bulk indexing into OpenSearch cluster", BATCH_LIMIT_FOR_BULK_INDEX);
                            }
                            br.set(new BulkRequest.Builder());
                        }
                        bulkCount.compareAndSet(BATCH_LIMIT_FOR_BULK_INDEX, 0);
                    } catch (JsonProcessingException e) {
                        log.error("Failed to serialize vulnerability {} into Java class: {}", vulnerabilityFilename, e.toString());
                    } catch (IOException e) {
                        log.error("Failed to index vulnerabilities into OpenSearch cluster", e);
                        throw new RuntimeException(e);
                    }
                }
            }
        });
        final BulkResponse result = openSearchClient.bulk(br.get().build());
        if (result.errors()) {
            log.error("Failed to bulk index some vulnerabilities into OpenSearch cluster");
            for (BulkResponseItem item: result.items()) {
                if (item.error() != null) {
                    log.error(item.error().reason());
                }
            }
        }
    }

    private void populateIntoPostgres(Stream<Path> vulnFileStream, AtomicInteger bulkCount) {
        final AtomicReference<List<Vulnerability>> vr = new AtomicReference<>(new ArrayList<>(BATCH_LIMIT_FOR_BULK_INDEX));

        vulnFileStream.forEach(p -> {
            final String vulnerabilityFilename = p.getFileName().toString();
            if (vulnerabilityFilename.endsWith(".json")) {
                String vulnerabilityString = "";
                try {
                    vulnerabilityString = Files.readString(p);
                } catch (IOException e) {
                    log.error("Failed to read vulnerability data from file {}: {}", vulnerabilityFilename, e.toString());
                }
                if (!vulnerabilityString.isBlank()) {
                    try {
                        final Vulnerability vulnerability = objectMapper.readValue(vulnerabilityString, Vulnerability.class);
                        vr.get().add(vulnerability);
                        bulkCount.addAndGet(1);
                        if (bulkCount.get() >= BATCH_LIMIT_FOR_BULK_INDEX) {
                            vulnerabilityRepository.saveAll(vr.get());
                            vr.set(new ArrayList<>());
                        }
                        bulkCount.compareAndSet(BATCH_LIMIT_FOR_BULK_INDEX, 0);
                    } catch (JsonProcessingException e) {
                        log.error("Failed to serialize vulnerability {} into Java class: {}", vulnerabilityFilename, e.toString());
                    }
                }
            }
        });

        // Persist any remaining vulns
        vulnerabilityRepository.saveAll(vr.get());
    }

    // Only load vulnerability data when whole application is ready.
    @EventListener(ApplicationReadyEvent.class)
    public void populateVulnerabilitiesIntoStorage() throws Exception {
        final OpenSearchClient openSearchClient = opensearchClientFactory.getOpensearchClient();

        // Create index if not exist.
        // TODO: Move this logic to IaC.
        final GetIndexRequest getIndexRequest = new GetIndexRequest.Builder()
                .index(indexName)
                .build();
        try {
            openSearchClient.indices().get(getIndexRequest);
        } catch (OpenSearchException getIndexException) {
            if (Objects.equals(getIndexException.error().type(), "index_not_found_exception")) {
                log.info("Index {} not yet created in OpenSearch cluster, creating one", indexName);
                // Have to do explicit mapping to `date` type for "modified", "published" and "withdrawn".
                final TypeMapping explicitDateMapping = new TypeMapping.Builder()
                        .properties("modified", new Property.Builder().date(
                                new DateProperty.Builder().build()).build())
                        .properties("published", new Property.Builder().date(
                                new DateProperty.Builder().build()).build())
                        .properties("withdrawn", new Property.Builder().date(
                                new DateProperty.Builder().build()).build())
                        .build();
                final CreateIndexRequest createIndexRequest = new CreateIndexRequest.Builder()
                        .index(indexName)
                        .mappings(explicitDateMapping)
                        .build();
                openSearchClient.indices().create(createIndexRequest);
                log.info("Index {} created", indexName);
            } else {
                throw getIndexException;
            }
        }

        // Walk through vulnerability files and bulk index them into the cluster.
        // Currently, we bulk indexes a batch of $BATCH_LIMIT_FOR_BULK_INDEX vulnerabilities.
        try (Stream<Path> vulnFileStream = Files.walk(Path.of(advisoryDatabasePath))) {
            final AtomicInteger bulkCount = new AtomicInteger();
            if (loadDataFromScratchIntoPostgresql) {
                populateIntoPostgres(vulnFileStream, bulkCount);
            }
            if (loadDataFromScratchIntoOpensearch) {
                populateIntoOpensearch(vulnFileStream, bulkCount);
            }
        }
    }
}
